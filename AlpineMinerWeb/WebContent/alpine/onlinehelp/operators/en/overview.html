<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
    <title>Overview</title>
</head>

<body style="font-family:Arial, Helvetica, sans-serif">
<h1>Overview</h1>
<p>The Alpine predictive analytics platform leverages the powerful parallel-processing technology of MPP databases and Hadoop to accomplish fast data-mining of massive data volumes on a cost-effective hardware platform.
    Alpine is built to operate within Hadoop environments and also the Greenplum, Oracle, Postgres, DB2, and Netezza database engines, ensuring that the data can be analyzed where it resides.</p>
<p>Alpine is a web-based application that enables users to build up sophisticated Analytics Workflows out of a sequence simple analytics functions (Operators) and apply them to data from a variety of Data Sources.
    Users create these flows in a drag-and-drop Workflow Editor, and then collaborate with other users by publishing, sharing and viewing their workflows in public groups.
</p>
<h2>Operators</h2>
<p>The Operator is the basic unit of the Data Mining Analytic Flow. Operators are grouped into the following categories</p>
<table border="1" cellspacing="0" cellpadding="0" width="511">
    <tr>
        <td width="171"><p align="center"><strong>Category</strong></p></td>
        <td width="340"><p align="center"><strong>Operator</strong></p></td>
    </tr>
    <tr>
        <td width="171" rowspan="4"><p align="left">Data Extraction</p></td>
        <td width="340"><p align="left">Dataset</p></td>
    </tr>
    <tr>
        <td width="340"><p>Hadoop File</p></td>
    </tr>
    <tr>
        <td width="340"><p>Copy To Database</p></td>
    </tr>
    <tr>
        <td width="340"><p>Copy To Hadoop</p></td>
    </tr>
    <tr>
        <td width="171" rowspan="9"><p align="left">Exploration</p></td>
        <td width="340"><p>Bar Chart Preview</p></td>
    </tr>
    <tr>
        <td width="340"><p>Correlation Analysis</p></td>
    </tr>
    <tr>
        <td width="340"><p>Frequency Analysis</p></td>
    </tr>
    <tr>
        <td width="340"><p>Histogram Analysis</p></td>
    </tr>
    <tr>
        <td width="340"><p>Univariate Analysis</p></td>
    </tr>
    <tr>
        <td width="340"><p>Summary Statistics</p></td>
    </tr>
    <tr>
        <td width="340"><p>Information Value Analysis</p></td>
    </tr>
    <tr>
        <td width="340"><p>Variable Selection</p></td>
    </tr>
    <tr>
        <td width="340"><p>Scatter Plot Matrix</p></td>
    </tr>
    <tr>
        <td width="171" rowspan="12"><p align="left">Transformation</p></td>
        <td width="340"><p>Table Set</p></td>
    </tr>
    <tr>
        <td width="340"><p>Aggregate</p></td>
    </tr>
    <tr>
        <td width="340"><p>Normalization</p></td>
    </tr>
    <tr>
        <td width="340"><p>Null Value Replacement</p></td>
    </tr>
    <tr>
        <td width="340"><p>Numeric To Text</p></td>
    </tr>
    <tr>
        <td width="340"><p>Pivot</p></td>
    </tr>
    <tr>
        <td width="340"><p>Row Filter</p></td>
    </tr>
    <tr>
        <td width="340"><p>Column Filter</p></td>
    </tr>
    <tr>
        <td width="340"><p>Table Join</p></td>
    </tr>
    <tr>
        <td width="340"><p>Variable</p></td>
    </tr>
    <tr>
        <td width="340"><p>Weight Of Evidence</p></td>
    </tr>
    <tr>
        <td width="340"><p>WOE Table Generator</p></td>
    </tr>
    <tr>
        <td width="171" rowspan="3"><p align="left">Sampling</p></td>
        <td width="340"><p>Random Sampling</p></td>
    </tr>
    <tr>
        <td width="340"><p>Stratified Sampling</p></td>
    </tr>
    <tr>
        <td width="340"><p>Sample Selector</p></td>
    </tr>
    <tr>
        <td width="171" rowspan="17"><p align="left">Model</p></td>
        <td width="340"><p>AdaBoost</p></td>
    </tr>
    <tr>
        <td width="340"><p>Association</p></td>
    </tr>
    <tr>
        <td width="340"><p>Cart Tree</p></td>
    </tr>
    <tr>
        <td width="340"><p>Decision Tree</p></td>
    </tr>
    <tr>
        <td width="340"><p>K-Means</p></td>
    </tr>
    <tr>
        <td width="340"><p>Linear Regression</p></td>
    </tr>
    <tr>
        <td width="340"><p>Logistic Regression</p></td>
    </tr>
    <tr>
        <td width="340"><p>Model</p></td>
    </tr>
    <tr>
        <td width="340"><p>Naive Bayes</p></td>
    </tr>
    <tr>
        <td width="340"><p>Neural Network</p></td>
    </tr>
    <tr>
        <td width="340"><p>Principal Component Analysis</p></td>
    </tr>
    <tr>
        <td width="340"><p>PLDA Trainer</p></td>
    </tr>
    <tr>
        <td width="340"><p>SVM Classification</p></td>
    </tr>
    <tr>
        <td width="340"><p>SVM Novelty Detection</p></td>
    </tr>
    <tr>
        <td width="340"><p>SVM Regression</p></td>
    </tr>
    <tr>
        <td width="340"><p>SVD</p></td>
    </tr>
    <tr>
        <td width="340"><p>Time Series</p></td>
    </tr>
    <tr>
        <td width="171" rowspan="13"><p align="left">Scoring</p></td>
        <td width="340"><p>AdaBoost Prediction</p></td>
    </tr>
    <tr>
        <td width="340"><p>Linear Regression Prediction</p></td>
    </tr>
    <tr>
        <td width="340"><p>Logistic Regression Prediction</p></td>
    </tr>
    <tr>
        <td width="340"><p>Naive Bayes Prediction</p></td>
    </tr>
    <tr>
        <td width="340"><p>Neural Network Prediction</p></td>
    </tr>
    <tr>
        <td width="340"><p>PLDA Prediction</p></td>
    </tr>
    <tr>
        <td width="340"><p>SVM Prediction</p></td>
    </tr>
    <tr>
        <td width="340"><p>Time Series Prediction</p></td>
    </tr>
    <tr>
        <td width="340"><p>Tree Prediction</p></td>
    </tr>
    <tr>
        <td width="340"><p>SVD Calculator</p></td>
    </tr>
    <tr>
        <td width="340"><p>Goodness Of Fit</p></td>
    </tr>
    <tr>
        <td width="340"><p>LIFT</p></td>
    </tr>
    <tr>
        <td width="340"><p>ROC</p></td>
    </tr>
    <tr>
        <td width="171" rowspan="3"><p align="left">Others</p></td>
        <td width="340"><p>SQL-Execute</p></td>
    </tr>
    <tr>
        <td width="340"><p>Sub Flow</p></td>
    </tr>
    <tr>
        <td width="340"><p>Note</p></td>
    </tr>
</table>
<p>&nbsp;</p>
<h2>Analytic Workflows</h2>
<p>The data mining process in Alpine is a flow of operators.
    Each operator takes input from the preceding operator(s), performs its task and produces output for the succeeding operators. Operators may have parameters which can be configured by the user and which may produce visual output within the user interface.
    Validation is performed when creating connections between operators and in configuring their parameters. Then, at run-time, information produced from an operator is passed to its succeeding operator(s). This forms an information flow through the operators during the flow execution
    which can be inspected and analyzed at any intermediate point.
</p>
<p><img src="./image/analytic_flow.png" width="524" height="280"></p>
<p><i>Input and output of an operator</i><br>
    The Analytic Flow Engine will check if the required inputs can be obtained from the preceding  operator(s). It will also determine the path of the operator flow, and any dependencies between operators will also be considered.
    The  Analytic Flow Engine also checks if all required parameters are present. If all  required parameters are not present, the flow will not start and errors will be reported to the user.</p>
<p>When  an operator has finished its task, the analytic engine will get the  operator&rsquo;s output, if there is any, and display it as a tab in the Workflow Result screen.</p>
<h2>Data Sources</h2>
<p>Data Source connection information is required for accessing the data in a database or Hadoop. In order to establish the required Data Source connections, which can be easily shared by different Operators in an Analytic Flow, Alpine provides a configuration dialog for managing the Data Source connection information.
    Details on creating and maintaining Data Sources will be discussed in the 'Data Sources' section.</p>
<p>Once Data Sources have been configured, the user is able to browse for tables and files of data in the Data Source Explorer, and then drag them into the Workflow Editor as the basis for analysis and modeling.
    Users may also upload additional data to the Data Sources for inclusion in their workflows.
</p>
<h2>Workflow Editor</h2>
<p>Analytic Flows are created and edited in the workflow editor. Users browse for data in the Data Source Explorer, add them to the workflow, and then begin applying operators in order to prepare the data, perform analyses, build models and produce model scores.
    Operators are joined together and configured in the editor, and users may save their work over time, with previous versions of the workflows available for reference or to be restored.
    As flows are built, they can be run in their entirety, or branches of them may be run using the 'step run' feature. Results are then reported back to the user in the Workflow Result window.
    Previous results are also available for comparison as workflows and data change over time.</p>
<p>Workflows may be shared with other users by saving them to a set of shared groups, and then copying them locally.
    Flows can also be exported as files that may be imported into another Alpine system. Finally, workflows may also be scheduled to be run regularly, and they can be exported as executable files that can be run independently, for example as part of a batch process.</p>
<p>Details  on creating a data mining Analytic Flow will be discussed in the section &lsquo;Editing Workflows&rsquo;.
</p>
</body>
</html>